{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/scottlew/miniconda3/lib/python3.6/site-packages/requests']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if needed: pip install requests or conda install requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "requests.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#timeDelay = random.randrange(2000, 4000)/1000\n",
    "#time.sleep(timeDelay)        \n",
    "#print(\"Scraped \" + str(url) + \"\\n\") \n",
    "#print(\"Waited \" + str(timeDelay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [x for x in range(1881,1890,1)]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#years = [1901,1902,1903,1904,1905,1906,1907,1908,1909,1910]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The functions scrape_bat  & scrape_pitch were used to obtain batting & pitching statistics from baseball-reference.com from 1876-2018 using BeautifulSoup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_bat(year):\n",
    "    # function reads in url for baseball referenece team batting stats\n",
    "    # and converts data into a Pandas dataframe which is written to a csv file\n",
    "    # table headers for batting stats on baseball-reference hardcoded\n",
    "    head = [ '#Bat', 'BatAge','R/G','G', 'PA','AB', 'R', 'H',\n",
    "       '2B', '3B', 'HR', 'RBI', 'SB', 'CS','BB', 'SO', 'BA', 'OBP',\n",
    "       'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB',\n",
    "       'LOB']\n",
    "    year =  year\n",
    "    url_name = 'https://www.baseball-reference.com/leagues/MLB/{}-standard-batting.shtml'\n",
    "    #url_name = 'https://www.baseball-reference.com/leagues/MLB/{}.shtml'\n",
    "    url = url_name.format(year)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success\")\n",
    "    else:\n",
    "        print(\"Sorry unable to connect to site\")\n",
    "\n",
    "    page = response.text\n",
    "    #from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(page, \"html\")\n",
    "    trow = soup.find_all('tr')\n",
    "    #Extract team names from team column which is in form of link not as <td>\n",
    "    teams = []\n",
    "    for row in trow:\n",
    "        for a in row.find_all('a'):\n",
    "            teams.append(a.text)\n",
    "\n",
    "    # Extract table data in this case batting stats\n",
    "    rows = []\n",
    "    for tr in trow:\n",
    "        td = tr.find_all('td')\n",
    "        row = [i.text for i in td]\n",
    "        #print(row)\n",
    "        rows.append(list(row))\n",
    "    #Create Pandas dataframe using rows\n",
    "    df = pd.DataFrame.from_records(rows)\n",
    "    df.columns = head\n",
    "    df = df.drop(df.index[-2]) # Drop last 2 rows\n",
    "    df = df.dropna()\n",
    "    df = df[:-1]\n",
    "    # Add the teams,Tm, column to DataFrame\n",
    "    df['Tm'] = teams\n",
    "\n",
    "    # Rearange dataframe so the last column becomes the first column\n",
    "    # see the following link for useful help\n",
    "    # https://stackoverflow.com/questions/13148429/how-to-change-the-order-of-dataframe-columns\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    # Add year column to DataFrame\n",
    "    df['Year'] = year\n",
    "    # Now save the dataframe for that year as a csv files\n",
    "    file_name = \"MLB_BAT_{}.csv\"\n",
    "    file = file_name.format(year)\n",
    "    df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_pitch(year):\n",
    "    # this function scrapes team pitching stats\n",
    "    # from baseball reference to extract Wins & Losses onlyy\n",
    "    # for each team in a year/season. It creates a csv file with 2 columns\n",
    "    # for later use\n",
    "    url_name = 'https://www.baseball-reference.com/leagues/MLB/{}-standard-pitching.shtml'\n",
    "    url = url_name.format(year)\n",
    "    year =  year\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success\")\n",
    "    else:\n",
    "        print(\"Sorry unable to connect to site\")\n",
    "\n",
    "    page = response.text\n",
    "    #from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(page, \"html\")\n",
    "\n",
    "    #Extract table rows\n",
    "    trow = soup.find_all('tr')\n",
    "    rows = []\n",
    "    for tr in trow:\n",
    "        td = tr.find_all('td')\n",
    "        row = [i.text for i in td]\n",
    "        #print(row)\n",
    "        rows.append(list(row))\n",
    "        \n",
    "    print(len(rows))\n",
    "    #Extract team names from column of team links\n",
    "    teams = []\n",
    "    for row in trow:\n",
    "        for a in row.find_all('a'):\n",
    "            teams.append(a.text)\n",
    "    \n",
    "    # Now create a pandas dataframe with the extracted rows\n",
    "    df = pd.DataFrame.from_records(rows)\n",
    "    df = df.drop(df.index[-2]) # drop last 2-3 rows which are averages 7/or sum of stats\n",
    "    df = df.dropna()\n",
    "    # Extract table headers\n",
    "    headers = soup.find_all('th')\n",
    "    thead = []\n",
    "    for h in headers:\n",
    "        thead.append(h.text)\n",
    "    print(thead)\n",
    "    print(len(thead))\n",
    "    print(teams)\n",
    "    \n",
    "    \n",
    "    # Add headers for new dataframe\n",
    "    # Get 104 headers only need 35, the first is the team column\n",
    "    # Add the team column last using teams list derived from find_all('a) above\n",
    "    #df.columns = thead[1:]\n",
    "    df.columns = thead[1:35]\n",
    "    #df.columns = thead\n",
    "    df = df[:-1] # drop the last row with funky data\n",
    "\n",
    "    # Add year column to DataFrame\n",
    "    df['Year'] = year\n",
    "    # Add teams columns\n",
    "    df['Tm'] = teams\n",
    "    # Next, reset the index of df and rearrange columns so Tm is the first columns\n",
    "    df.reset_index(drop=True)\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    # Now save the dataframe for that year as a csv files\n",
    "    file_name = \"MLB_Pitch_{}.csv\"\n",
    "    file = file_name.format(year)\n",
    "    df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_teams(year):\n",
    "    # function reads in url for baseball reference team batting stats\n",
    "    # and converts data into a Pandas dataframe which is written to a csv file\n",
    "    # table headers for batting stats on baseball-reference hardcoded\n",
    "    head = [ '#Bat', 'BatAge','R/G','G', 'PA','AB', 'R', 'H',\n",
    "       '2B', '3B', 'HR', 'RBI', 'SB', 'CS','BB', 'SO', 'BA', 'OBP',\n",
    "       'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB',\n",
    "       'LOB']\n",
    "    year =  year\n",
    "    url_name = 'https://www.baseball-reference.com/leagues/MLB/{}.shtml'\n",
    "    url = url_name.format(year)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success\")\n",
    "    else:\n",
    "        print(\"Sorry unable to connect to site\")\n",
    "\n",
    "    page = response.text\n",
    "    #from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(page, \"html\")\n",
    "    trow = soup.find_all('tr')\n",
    "    links = soup.findAll('a')\n",
    "    #Extract team names from team column which is in form of link not as <td>\n",
    "    teams = []\n",
    "    #table = html.find('table', 't1')\n",
    "    #links = trow.findAll('a')\n",
    "    #tags = soup.find_all('a')\n",
    "    #for row in trow[0]:\n",
    "        #for a in row.find_all('a'):\n",
    "            #teams.append(a.text)\n",
    "    \n",
    "        \n",
    "\n",
    "    print(links)\n",
    "    #print(len(teams))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitching Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "11\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BSN', 'BUF', 'CHC', 'CLV', 'DTN', 'PRO', 'TRO', 'WOR', 'LgAvg', '']\n",
      "45\n",
      "['BSN', 'BUF', 'CHC', 'CLV', 'DTN', 'PRO', 'TRO', 'WOR']\n",
      "Success\n",
      "17\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BAL', 'BSN', 'BUF', 'CHC', 'CIN', 'CLV', 'DTN', 'LOU', 'PHA', 'PIT', 'PRO', 'STL', 'TRO', 'WOR', 'LgAvg', '']\n",
      "51\n",
      "['BAL', 'BSN', 'BUF', 'CHC', 'CIN', 'CLV', 'DTN', 'LOU', 'PHA', 'PIT', 'PRO', 'STL', 'TRO', 'WOR']\n",
      "Success\n",
      "19\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BAL', 'BSN', 'BUF', 'CHC', 'CIN', 'CLV', 'COL', 'DTN', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'PRO', 'STL', 'LgAvg', '']\n",
      "53\n",
      "['BAL', 'BSN', 'BUF', 'CHC', 'CIN', 'CLV', 'COL', 'DTN', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'PRO', 'STL']\n",
      "Success\n",
      "37\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'ALT', 'BAL', 'BLU', 'BOS', 'BRO', 'BSN', 'BUF', 'CHC', 'CIN', 'CLV', 'COL', 'COR', 'CPI', 'DTN', 'IND', 'KCC', 'LOU', 'MIL', 'NYG', 'NYP', 'PHA', 'PHI', 'PHK', 'PIT', 'PRO', 'RIC', 'SLM', 'STL', 'STP', 'TOL', 'WAS', 'WHS', 'WIL', 'LgAvg', '', 'Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W']\n",
      "105\n",
      "['ALT', 'BAL', 'BLU', 'BOS', 'BRO', 'BSN', 'BUF', 'CHC', 'CIN', 'CLV', 'COL', 'COR', 'CPI', 'DTN', 'IND', 'KCC', 'LOU', 'MIL', 'NYG', 'NYP', 'PHA', 'PHI', 'PHK', 'PIT', 'PRO', 'RIC', 'SLM', 'STL', 'STP', 'TOL', 'WAS', 'WHS', 'WIL']\n",
      "Success\n",
      "19\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BAL', 'BRO', 'BSN', 'BUF', 'CHC', 'CIN', 'DTN', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'PRO', 'SLM', 'STL', 'LgAvg', '']\n",
      "53\n",
      "['BAL', 'BRO', 'BSN', 'BUF', 'CHC', 'CIN', 'DTN', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'PRO', 'SLM', 'STL']\n",
      "Success\n",
      "19\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'DTN', 'KCN', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'SLM', 'STL', 'WHS', 'LgAvg', '']\n",
      "53\n",
      "['BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'DTN', 'KCN', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'SLM', 'STL', 'WHS']\n",
      "Success\n",
      "19\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'CLE', 'DTN', 'IND', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'STL', 'WHS', 'LgAvg', '']\n",
      "53\n",
      "['BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'CLE', 'DTN', 'IND', 'LOU', 'NYG', 'NYP', 'PHA', 'PHI', 'PIT', 'STL', 'WHS']\n",
      "Success\n",
      "19\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'CLE', 'DTN', 'IND', 'KCC', 'LOU', 'NYG', 'PHA', 'PHI', 'PIT', 'STL', 'WHS', 'LgAvg', '']\n",
      "53\n",
      "['BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'CLE', 'DTN', 'IND', 'KCC', 'LOU', 'NYG', 'PHA', 'PHI', 'PIT', 'STL', 'WHS']\n",
      "Success\n",
      "19\n",
      "['Tm', '#P', 'PAge', 'RA/G', 'W', 'L', 'W-L%', 'ERA', 'G', 'GS', 'GF', 'CG', 'tSho', 'cSho', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'BK', 'WP', 'BF', 'ERA+', 'FIP', 'WHIP', 'H9', 'HR9', 'BB9', 'SO9', 'SO/W', 'BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'CLV', 'COL', 'IND', 'KCC', 'LOU', 'NYG', 'PHA', 'PHI', 'PIT', 'STL', 'WHS', 'LgAvg', '']\n",
      "53\n",
      "['BAL', 'BRO', 'BSN', 'CHC', 'CIN', 'CLV', 'COL', 'IND', 'KCC', 'LOU', 'NYG', 'PHA', 'PHI', 'PIT', 'STL', 'WHS']\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Scrape for pitchings stats\n",
    "#years = [1901,1902,1903,1904,1905,1906,1907,1908,1909,1910]\n",
    "#years = [1880]\n",
    "\n",
    "for year in years:\n",
    "    # scrape table for each season\n",
    "    scrape_pitch(year)\n",
    "    \n",
    "    time.sleep(25)\n",
    "    \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note Too many anchor tags/href are being scrapped... in this case twice as many, team names are appended twice to list called teams. Note: problem seems corrected using new url for batting stats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Batting Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrape for batting stats\n",
    "#years = [x for x in range(1891,1900,1)]\n",
    "#years\n",
    "#years = [1880]\n",
    "for year in years:\n",
    "    scrape_bat(year)\n",
    "   \n",
    "    time.sleep(20)\n",
    "    \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape for pitchings stats\n",
    "#years = [1901,1902,1903,1904,1905,1906,1907,1908,1909,1910]\n",
    "#years = [1960]\n",
    "\n",
    "#for year in years:\n",
    "    # scrape table for each season\n",
    "    #scrape_pitch(year)\n",
    "    \n",
    "    #time.sleep(15)\n",
    "    \n",
    "#print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RUN ABOVE CODE FROM HERE TO SCRAPE PITCHING & BATTING STATS FROM BASEBALL_REFERENCE WEB SITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrape for batting stats\n",
    "#years = [1990,1991,1992,1993,1994,1995,1996,1997,1998,1999]\n",
    "years = [1960]\n",
    "#for year in years:\n",
    "    #scrape_teams(year)\n",
    "   \n",
    "    #time.sleep(15)\n",
    "    \n",
    "print(\"DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
